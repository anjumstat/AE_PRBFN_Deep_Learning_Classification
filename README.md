# AE_PRBFN_Deep_Learning_Classification
# Genomic Data Processing Pipeline: From Raw CDS to Curated Datasets

This repository contains a pipeline for downloading and rigorously curating Coding DNA Sequence (CDS) data from Ensembl Plants for use in genomic studies and machine learning projects.

## Pipeline Overview

### Step 1: Data Acquisition from Ensembl Plants
**Script:** Manual Download / `wget` or `rsync` commands
**Description:** CDS sequences in FASTA format were downloaded for four grass species (*Brachypodium distachyon*, *Hordeum vulgare*, *Oryza sativa*, *Triticum aestivum*) from the [Ensembl Plants](http://plants.ensembl.org/) database. This step involves:
- Navigating to the Ensembl Plants website
- Selecting the target species
- Accessing the "Gene" section
- Downloading the "CDS" FASTA files for each species
- Ensuring data version consistency (e.g., Release 60)

### Step 2: CDS Validation and Filtering
**Script:** `CDS_Validation_Pipeline.py`
**Description:** This core script performs rigorous quality control on the raw FASTA files from Ensembl through seven sequential biological validation checks:

1.  **Length Check:** Sequence length is divisible by 3.
2.  **Base Validation:** Contains only standard DNA bases (`A`, `T`, `C`, `G`).
3.  **Start Codon:** Must begin with the canonical start codon `ATG`.
4.  **Stop Codon:** Must end with a valid stop codon (`TAA`, `TAG`, or `TGA`).
5.  **Internal Stops:** Must contain no internal stop codons.
6.  **Translation:** Must successfully translate to an amino acid sequence using the standard genetic code.
7.  **Length Consistency:** The translated protein length must be consistent with the DNA sequence length.

## Usage

1.  **Acquire Data:** Download CDS FASTA files for your target species from [Ensembl Plants](http://plants.ensembl.org/).
2.  **Configure Paths:** Edit the following variables in `CDS_Validation_Pipeline.py`:
    ```python
    input_dir = r"path/to/your/raw/ensembl/fasta/files"
    output_dir = r"path/to/your/filtered/output/directory"
    ```
3.  **Run the Pipeline:**
    ```bash
    python CDS_Validation_Pipeline.py
    ```

## Outputs

*   **Filtered FASTA Files:** For each input species file, a new filtered file (suffix `_filtered.fasta`) is generated, containing only sequences that passed all biological criteria.
*   **Detailed CSV Report:** A comprehensive statistics file (`filtering_stats.csv`) logs the number of sequences discarded at each filtering step, providing full transparency into the data curation process.

## Dependencies

*   Python 3.x
*   Biopython (`pip install biopython`)

## Use Case

This end-to-end pipeline is designed for:
- Creating high-quality, reliable datasets for phylogenetic analysis
- Preparing data for molecular evolutionary studies (e.g., dN/dS calculation)
- Curating training data for machine learning models in genomics
- Generating benchmark datasets for comparative genomics

**Note:** The filtering statistics generated by this pipeline were used to create Table 1 in the associated manuscript, demonstrating the rigorous quality control applied to the training data.
